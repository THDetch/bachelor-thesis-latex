@article{huang2015,
  title   = {Cloud removal from optical satellite imagery with SAR imagery using sparse representation},
  author  = {Huang, Bo and Li, Yansong and Han, Xiaoying and Cui, Yu and Li, Wei and Li, Rui},
  journal = {IEEE Geoscience and Remote Sensing Letters},
  volume  = {12},
  number  = {5},
  pages   = {1046--1050},
  year    = {2015}
}

@article{CR_spars_repre_MT_dict_L,
  title   = {Cloud removal based on sparse representation via multitemporal dictionary learning},
  author  = {Xu, Mingsheng and Jia, Xiuping and Pickering, Mark and Plaza, Antonio J},
  journal = {IEEE Transactions on Geoscience and Remote Sensing},
  volume  = {54},
  number  = {5},
  pages   = {2998--3006},
  year    = {2016}
}

@misc{cGANs_mirza,
  title         = {Conditional generative adversarial nets},
  author        = {Mirza, Mehdi and Osindero, Simon},
  year          = {2014},
  eprint        = {1411.1784},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/1411.1784}
}

@misc{cycle_GANs,
  title         = {Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks},
  author        = {Jun-Yan Zhu and Taesung Park and Phillip Isola and Alexei A. Efros},
  year          = {2020},
  eprint        = {1703.10593},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV},
  url           = {https://arxiv.org/abs/1703.10593}
}

@article{swinunet2023,
  title     = {Swin-{UN}et: \textit{Unet}-like pure transformer for medical image segmentation},
  author    = {Cao, Hui and Wang, Yanning and Chen, Jianlong and Jiang, Dongsheng and Zhang, Xin and Tian, Qi and Wang, Miaomiao},
  booktitle = {In Computer Vision – ECCV 2022 Workshops},
  pages     = {205--218},
  year      = {2023}
}

@article{enomoto2017,
  title   = {Image restoration from satellite cloud contamination using multispectral conditional GAN},
  author  = {Enomoto, Ryosuke and others},
  journal = {Remote Sensing (likely)},
  year    = {2017}
}

@inproceedings{A_cGAN_fuse_sar_MS_CR,
  title     = {A conditional generative adversarial network to fuse SAR and multispectral optical data for cloud removal from Sentinel-2 images},
  author    = {Grohnfeldt, Claas and Schmitt, Michael and Zhu, Xiao Xiang},
  booktitle = {ISPRS TC III Mid-term Symposium},
  year      = {2018}
}

@inproceedings{syn_ms_sar_opt_MT_cGAN,
  title     = {Synthesis of multispectral optical images from SAR/optical multitemporal data using conditional GANs},
  author    = {Bermudez, Jose and Happ, Philipp and Boulch, Alexandre and others},
  booktitle = {IGARSS},
  year      = {2018}
}

@inproceedings{sen12_2018,
  title     = {The SEN1-2 dataset for deep learning in SAR-optical data fusion},
  author    = {Schmitt, Michael and Hughes, L. H. and Zhu, Xiao Xiang},
  booktitle = {ISPRS Annals of Photogrammetry, Remote Sensing and Spatial Information Sciences},
  volume    = {IV-1},
  pages     = {141--146},
  year      = {2018}
}

@inproceedings{sen12ms_2019,
  title     = {SEN12MS--A curated dataset of georeferenced multi-spectral Sentinel-1/2 imagery for deep learning and data fusion},
  author    = {Schmitt, Michael and Hughes, L. H. and Qiu, C. and Zhu, Xiao Xiang},
  booktitle = {ISPRS Annals of Photogrammetry, Remote Sensing and Spatial Information Sciences},
  volume    = {IV-2/W7},
  pages     = {153--160},
  year      = {2019}
}

@article{sen12ms-cr_2021,
  author   = {Ebel, Patrick and Meraner, Andrea and Schmitt, Michael and Zhu, Xiao Xiang},
  journal  = {IEEE Transactions on Geoscience and Remote Sensing},
  title    = {Multisensor Data Fusion for Cloud Removal in Global and All-Season Sentinel-2 Imagery},
  year     = {2021},
  volume   = {59},
  number   = {7},
  pages    = {5866-5878},
  keywords = {Clouds;Optical imaging;Cloud computing;Earth;Optical sensors;Data integration;Image reconstruction;Cloud removal;data fusion;deep learning;generative adversarial network (GAN);optical imagery;synthetic aperture radar (SAR)-optical},
  doi      = {10.1109/TGRS.2020.3024744}
}

@article{sen12ms-cr-ts_2022,
  author   = {Ebel, Patrick and Xu, Yajin and Schmitt, Michael and Zhu, Xiao Xiang},
  journal  = {IEEE Transactions on Geoscience and Remote Sensing},
  title    = {SEN12MS-CR-TS: A Remote-Sensing Data Set for Multimodal Multitemporal Cloud Removal},
  year     = {2022},
  volume   = {60},
  number   = {},
  pages    = {1-14},
  keywords = {Clouds;Optical imaging;Optical sensors;Satellites;Remote sensing;Image reconstruction;Earth;Cloud removal;data fusion;image reconstruction;sequence-to-sequence;synthetic aperture radar (SAR)-optical;time series},
  doi      = {10.1109/TGRS.2022.3146246}
}

@article{sar2opt_cGAN_Optim_oppr_limits,
  title   = {SAR-to-Optical Image Translation Based on Conditional Generative Adversarial Networks—Optimization, Opportunities and Limits},
  author  = {Fuentes Reyes, M. and Auer, S. and Merkle, N. and Henry, C. and Schmitt, M.},
  journal = {Remote Sensing},
  volume  = {11},
  number  = {17},
  pages   = {2067},
  year    = {2019}
}

@article{wang2019,
  title   = {SAR-to-optical image translation using supervised cycle-consistent adversarial networks},
  author  = {Wang, L. and Xu, X. and Yu, Y. and Yang, R. and Gui, R. and Xu, Z. and Pu, F.},
  journal = {IEEE Access},
  volume  = {7},
  pages   = {129136--129149},
  year    = {2019}
}

@inproceedings{GAN_gen_synt_MS,
  author    = {{Abady}, L. and {Barni}, M. and {Garzelli}, A. and {Tondi}, B.},
  title     = {{GAN generation of synthetic multispectral satellite images}},
  booktitle = {Image and Signal Processing for Remote Sensing XXVI},
  year      = 2020,
  editor    = {{Bruzzone}, Lorenzo and {Bovolo}, Francesca and {Benediktsson}, Jon Atli and {Bovenga}, Fabio and {Notarnicola}, Claudia and {Pierdicca}, Nazzareno and {Santi}, Emanuele},
  series    = {Society of Photo-Optical Instrumentation Engineers (SPIE) Conference Series},
  volume    = {11533},
  month     = sep,
  eid       = {115330L},
  pages     = {115330L},
  doi       = {10.1117/12.2575765},
  adsurl    = {https://ui.adsabs.harvard.edu/abs/2020SPIE11533E..0LA},
  adsnote   = {Provided by the SAO/NASA Astrophysics Data System}
}


@misc{CR_RS_spati_atten_GAN,
  title         = {Cloud removal for remote sensing imagery via spatial attention generative adversarial network},
  author        = {Pan, B. and others},
  year          = {2020},
  eprint        = {2009.13015},
  archiveprefix = {arXiv}
}

@article{gao2020,
  title   = {Cloud removal with fusion of high-resolution optical and SAR images using generative adversarial networks},
  author  = {Gao, Feng and others},
  journal = {Remote Sensing},
  volume  = {12},
  number  = {1},
  pages   = {191},
  year    = {2020}
}

@inproceedings{naderi2021,
  title     = {Cloud removal in remote sensing images using generative adversarial networks with dilated residual inception blocks},
  author    = {Naderi Darbaghshahi, F. and Mohammadi, M. R.},
  booktitle = {IGARSS},
  year      = {2021}
}

@article{CR_RS_GAN_s2o,
  author   = {Darbaghshahi, Faramarz Naderi and Mohammadi, Mohammad Reza and Soryani, Mohsen},
  journal  = {IEEE Transactions on Geoscience and Remote Sensing},
  title    = {Cloud Removal in Remote Sensing Images Using Generative Adversarial Networks and SAR-to-Optical Image Translation},
  year     = {2022},
  volume   = {60},
  number   = {},
  pages    = {1-9},
  keywords = {Clouds;Generative adversarial networks;Optical imaging;Generators;Optical sensors;Synthetic aperture radar;Radar polarimetry;Cloud removal;deep learning;generative adversarial network (GAN);optical imagery;SAR-to-optical translation;synthetic aperture radar (SAR)},
  doi      = {10.1109/TGRS.2021.3131035}
}


@article{UnCRtainTS,
  title   = {UnCRtainTS: Uncertainty quantification for cloud removal in optical satellite time series},
  author  = {Ebel, P. and others},
  journal = {arXiv preprint},
  eprint  = {2304.05464},
  year    = {2022}
}

@article{c_diffusion_s2o,
  title   = {Conditional diffusion for SAR to optical image translation},
  author  = {Bai, W. and others},
  journal = {IEEE Transactions on Geoscience and Remote Sensing},
  year    = {2023}
}

@misc{DiffCR,
  title         = {DiffCR: A fast conditional diffusion framework for cloud removal from optical satellite images},
  author        = {Zou, H. and others},
  year          = {2023},
  eprint        = {2308.04417},
  archiveprefix = {arXiv}
}

@misc{s2o_color_super_diff,
  title         = {SAR to Optical Image Translation with Color Supervised Diffusion Model},
  author        = {Xinyu Bai and Feng Xu},
  year          = {2024},
  eprint        = {2407.16921},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV},
  url           = {https://arxiv.org/abs/2407.16921}
}


@article{assessing_MT_cGANS_s2o_crop,
  title   = {Assessing the potential of multi-temporal conditional GANs in SAR-to-optical image translation for early-stage crop monitoring},
  author  = {Kwak, H. and Park, S.},
  journal = {Remote Sensing},
  volume  = {16},
  number  = {7},
  pages   = {1199},
  year    = {2024}
}

@article{S2MS_GAN,
  title   = {High-Resolution SAR-to-Multispectral Image Translation Based on S2MS-GAN},
  author  = {Liu, J. and others},
  journal = {Remote Sensing},
  volume  = {16},
  number  = {21},
  pages   = {4045},
  year    = {2024}
}

@article{dosovitskiy2020,
  title   = {An image is worth 16×16 words: Transformers for image recognition at scale},
  author  = {Dosovitskiy, A. and others},
  journal = {arXiv preprint},
  eprint  = {2010.11929},
  year    = {2020}
}

@inproceedings{s2o_ViT_cGAN,
  title     = {SAR-to-optical image translation using Vision Transformer-based cGAN},
  author    = {Park, S. and others},
  booktitle = {IGARSS},
  year      = {2025}
}

@article{gu2023,
  title   = {Mamba: Linear-time sequence modeling with selective state spaces},
  author  = {Gu, A. and Dao, T.},
  journal = {arXiv preprint},
  eprint  = {2312.00752},
  year    = {2023}
}

@article{umamba2024,
  title   = {U-Mamba: Enhancing Long-range Dependency for Biomedical Image Segmentation},
  author  = {Ma, Jun and Li, Feifei and Wang, Bo},
  journal = {arXiv preprint},
  eprint  = {2401.04722},
  year    = {2024}
}

@article{swinumamba2024,
  title   = {Swin-UMamba: Mamba-based UNet with ImageNet-based pretraining},
  author  = {Liu, Jiarun and Yang, Hao and Zhou, Hong-Yu and Xi, Yan and Yu, Lequan and Yu, Yizhou and Liang, Yong and Shi, Guangming and Zhang, Shaoting and Zheng, Hairong and Wang, Shanshan},
  journal = {arXiv preprint},
  eprint  = {2402.03302},
  year    = {2024}
}

@inproceedings{swinumamba2024micipai,
  title     = {Swin-UMamba: Mamba-based UNet with ImageNet-based pretraining},
  author    = {Liu, Jiarun and others},
  booktitle = {MICCAI 2024 Workshop},
  year      = {2024}
}


@incollection{book_Physics_Techniques_RS,
  title     = {Introduction},
  booktitle = {Introduction to the Physics and Techniques of Remote Sensing},
  author    = {Charles Elachi and Jakob van Zyl},
  chapter   = {1},
  pages     = {1--18},
  publisher = {John Wiley \& Sons, Ltd},
  year      = {2021},
  isbn      = {9781119523048},
  doi       = {10.1002/9781119523048.ch1},
  url       = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9781119523048.ch1}
}

@incollection{book_Satellite_RS,
  author    = {Chuvieco, Emilio},
  title     = {Introduction},
  booktitle = {Fundamentals of Satellite Remote Sensing: An Environmental Approach},
  publisher = {CRC Press},
  year      = {2020},
  doi       = {10.1201/9780429506482},
  isbn      = {9780429506482},
  url       = {https://www.taylorfrancis.com/books/mono/10.1201/9780429506482/fundamentals-satellite-remote-sensing-emilio-chuvieco}
}

@article{Landsat-8,
  title    = {Landsat-8: Science and product vision for terrestrial global change research},
  journal  = {Remote Sensing of Environment},
  volume   = {145},
  pages    = {154-172},
  year     = {2014},
  issn     = {0034-4257},
  doi      = {https://doi.org/10.1016/j.rse.2014.02.001},
  url      = {https://www.sciencedirect.com/science/article/pii/S003442571400042X},
  author   = {D.P. Roy and M.A. Wulder and T.R. Loveland and Woodcock C.E. and R.G. Allen and M.C. Anderson and D. Helder and J.R. Irons and D.M. Johnson and R. Kennedy and T.A. Scambos and C.B. Schaaf and J.R. Schott and Y. Sheng and E.F. Vermote and A.S. Belward and R. Bindschadler and W.B. Cohen and F. Gao and J.D. Hipple and P. Hostert and J. Huntington and C.O. Justice and A. Kilic and V. Kovalskyy and Z.P. Lee and L. Lymburner and J.G. Masek and J. McCorkel and Y. Shuai and R. Trezza and J. Vogelmann and R.H. Wynne and Z. Zhu},
  keywords = {Landsat 8, OLI, TIRS, Landsat Science Team}
}

@article{RS_platforms_survey,
  title    = {Remote sensing platforms and sensors: A survey},
  journal  = {ISPRS Journal of Photogrammetry and Remote Sensing},
  volume   = {115},
  pages    = {22-36},
  year     = {2016},
  note     = {Theme issue 'State-of-the-art in photogrammetry, remote sensing and spatial information science'},
  issn     = {0924-2716},
  doi      = {https://doi.org/10.1016/j.isprsjprs.2015.10.004},
  url      = {https://www.sciencedirect.com/science/article/pii/S0924271615002270},
  author   = {Charles Toth and Grzegorz Jóźków},
  keywords = {Remote sensing, Imaging sensors, Cameras, Platforms, Satellites, UAS, Georeferencing}
}

@incollection{Aschbacher2017,
  title     = {ESA's Earth Observation Strategy and Copernicus},
  booktitle = {Satellite Earth Observations and Their Impact on Society and Policy},
  author    = {Aschbacher, Josef},
  pages     = {81--86},
  publisher = {Springer Singapore},
  year      = {2017},
  isbn      = {978-981-10-3713-9},
  doi       = {10.1007/978-981-10-3713-9_5},
  url       = {https://doi.org/10.1007/978-981-10-3713-9_5}
}

@online{ESA_Copernicus,
  author = {{European Space Agency (ESA)}},
  title  = {Copernicus: Sentinel Missions},
  year   = {2024},
  url    = {https://www.esa.int/Applications/Observing_the_Earth/Copernicus},
  note   = {Accessed: 3 September 2025}
}

@online{ESA_SentinelMissions,
  author = {{European Space Agency}},
  title  = {Copernicus: Sentinel Missions},
  year   = {2024},
  url    = {https://sentinels.copernicus.eu/missions},
  note   = {Accessed: 3 September 2025}
}

@online{sentiwiki,
  author = {{European Space Agency (ESA)}},
  title  = {SentiWiki -- Copernicus Sentinels},
  year   = {2025},
  url    = {https://sentiwiki.copernicus.eu/web/},
  note   = {Accessed: 6 September 2025}
}


@article{dl_cloud_detection_survey,
  author         = {Wang, Zhengxin and Zhao, Longlong and Meng, Jintao and Han, Yu and Li, Xiaoli and Jiang, Ruixia and Chen, Jinsong and Li, Hongzhong},
  title          = {Deep Learning-Based Cloud Detection for Optical Remote Sensing Images: A Survey},
  journal        = {Remote Sensing},
  volume         = {16},
  year           = {2024},
  number         = {23},
  article-number = {4583},
  url            = {https://www.mdpi.com/2072-4292/16/23/4583},
  issn           = {2072-4292},
  doi            = {10.3390/rs16234583}
}

@inproceedings{aCGAN_fuse_sar_MS,
  author    = {Grohnfeldt, Claas and Schmitt, Michael and Zhu, Xiaoxiang},
  booktitle = {IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium},
  title     = {A Conditional Generative Adversarial Network to Fuse Sar And Multispectral Optical Data For Cloud Removal From Sentinel-2 Images},
  year      = {2018},
  volume    = {},
  number    = {},
  pages     = {1726-1729},
  keywords  = {Synthetic aperture radar;Optical sensors;Optical imaging;Clouds;Remote sensing;Adaptive optics;Generative adversarial networks;SAR;optical remote sensing;data fusion;deep learning;generative adversarial network (GAN);cloud-removal},
  doi       = {10.1109/IGARSS.2018.8519215}
}

@article{CR_SEN2_dRNN,
  title    = {Cloud removal in Sentinel-2 imagery using a deep residual neural network and SAR-optical data fusion},
  journal  = {ISPRS Journal of Photogrammetry and Remote Sensing},
  volume   = {166},
  pages    = {333-346},
  year     = {2020},
  issn     = {0924-2716},
  doi      = {https://doi.org/10.1016/j.isprsjprs.2020.05.013},
  url      = {https://www.sciencedirect.com/science/article/pii/S0924271620301398},
  author   = {Andrea Meraner and Patrick Ebel and Xiao Xiang Zhu and Michael Schmitt},
  keywords = {Cloud removal, Optical imagery, SAR-optical, Data fusion, Deep learning, Residual network}
}

    
@article{sar_2_opt_CGAN_survey_taxonomy,
  author         = {Xiong, Quan and Li, Guoqing and Yao, Xiaochuang and Zhang, Xiaodong},
  title          = {SAR-to-Optical Image Translation and Cloud Removal Based on Conditional Generative Adversarial Networks: Literature Survey, Taxonomy, Evaluation Indicators, Limits and Future Directions},
  journal        = {Remote Sensing},
  volume         = {15},
  year           = {2023},
  number         = {4},
  article-number = {1137},
  url            = {https://www.mdpi.com/2072-4292/15/4/1137},
  issn           = {2072-4292},
  doi            = {10.3390/rs15041137}
}

@article{CR_Advances_Review_ORS,
  author   = {Ning, Jin and Xie, Lianbin and Yin, Jie and Liu, Yiguang},
  journal  = {IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
  title    = {Cloud Removal Advances: A Comprehensive Review and Analysis for Optical Remote Sensing Images},
  year     = {2025},
  volume   = {18},
  number   = {},
  pages    = {15914-15930},
  keywords = {Clouds;Remote sensing;Image color analysis;Reviews;Market research;Earth;Image restoration;Accuracy;Deep learning;Visualization;Cloud removal;multimodal;multitemporal;optical remote sensing (ORS);single-image},
  doi      = {10.1109/JSTARS.2025.3580718}
}



@misc{s2o_Thermodynamics,
  title         = {SAR-to-Optical Image Translation via Thermodynamics-inspired Network},
  author        = {Mingjin Zhang and Jiamin Xu and Chengyu He and Wenteng Shang and Yunsong Li and Xinbo Gao},
  year          = {2023},
  eprint        = {2305.13839},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV},
  url           = {https://arxiv.org/abs/2305.13839}
}

@article{SAR_DeCR,
  author         = {Wang, Meilin and Hu, Shihao and Song, Yexing and Shi, Yukai},
  title          = {SAR-DeCR: Latent Diffusion for SAR-Fused Thick Cloud Removal},
  journal        = {Remote Sensing},
  volume         = {17},
  year           = {2025},
  number         = {13},
  article-number = {2241},
  url            = {https://www.mdpi.com/2072-4292/17/13/2241},
  issn           = {2072-4292},
  doi            = {10.3390/rs17132241}
}

@article{single_variation,
  title   = {An image transform to characterize and compensate for spatial variations in thin cloud contamination of Landsat images},
  journal = {Remote Sensing of Environment},
  volume  = {82},
  number  = {2},
  pages   = {173-187},
  year    = {2002},
  issn    = {0034-4257},
  doi     = {https://doi.org/10.1016/S0034-4257(02)00034-2},
  url     = {https://www.sciencedirect.com/science/article/pii/S0034425702000342},
  author  = {Y Zhang and B Guindon and J Cihlar}
}

@inproceedings{single_haze_removal_dark_prior,
  author    = {Kaiming He and Jian Sun and Xiaoou Tang},
  booktitle = {2009 IEEE Conference on Computer Vision and Pattern Recognition},
  title     = {Single image haze removal using dark channel prior},
  year      = {2009},
  volume    = {},
  number    = {},
  pages     = {1956-1963},
  keywords  = {Statistics;Pixel},
  doi       = {10.1109/CVPR.2009.5206515}
}

@inproceedings{single_artifact_free_CR_GAN,
  author    = {Toizumi, Takahiro and Zini, Simone and Sagi, Kazutoshi and Kaneko, Eiji and Tsukada, Masato and Schettini, Raimondo},
  booktitle = {2019 IEEE International Conference on Image Processing (ICIP)},
  title     = {Artifact-Free Thin Cloud Removal Using Gans},
  year      = {2019},
  volume    = {},
  number    = {},
  pages     = {3596-3600},
  keywords  = {Clouds;Training;Gallium nitride;Generators;Remote sensing;Agriculture;Feature extraction;Remote sensing;Generative adversarial nets;Multi-spectral image;Cloud removal.},
  doi       = {10.1109/ICIP.2019.8803652}
}

@article{single_thin_CR_ORS_GAN_phys,
  title    = {Thin cloud removal in optical remote sensing images based on generative adversarial networks and physical model of cloud distortion},
  journal  = {ISPRS Journal of Photogrammetry and Remote Sensing},
  volume   = {166},
  pages    = {373-389},
  year     = {2020},
  issn     = {0924-2716},
  doi      = {https://doi.org/10.1016/j.isprsjprs.2020.06.021},
  url      = {https://www.sciencedirect.com/science/article/pii/S0924271620301787},
  author   = {Jun Li and Zhaocong Wu and Zhongwen Hu and Jiaqi Zhang and Mingliang Li and Lu Mo and Matthieu Molinier},
  keywords = {Cloud removal, Thin clouds, Physical model of cloud distortion, Generative Adversarial Networks (GANs), Image decomposition}
}

@inproceedings{single_multi_DR_CR,
  author    = {Yang, Qiaoqiao and Wang, Guangxing and Zhao, Yaxuan and Zhang, Xiaoyu and Dong, Guoshuai and Ren, Peng},
  booktitle = {IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium},
  title     = {Multi-Scale Deep Residual Learning for Cloud Removal},
  year      = {2020},
  volume    = {},
  number    = {},
  pages     = {4967-4970},
  keywords  = {Clouds;Remote sensing;Convolution;Feature extraction;Cloud computing;Residual neural networks;Transforms;Cloud Removal;Multi-Scale;Residual Network;Deep Learning},
  doi       = {10.1109/IGARSS39084.2020.9323261}
}

@article{single_CR_DLM_matting,
  author         = {Ma, Deying and Wu, Renzhe and Xiao, Dongsheng and Sui, Baikai},
  title          = {Cloud Removal from Satellite Images Using a Deep Learning Model with the Cloud-Matting Method},
  journal        = {Remote Sensing},
  volume         = {15},
  year           = {2023},
  number         = {4},
  article-number = {904},
  url            = {https://www.mdpi.com/2072-4292/15/4/904},
  issn           = {2072-4292},
  doi            = {10.3390/rs15040904}
}

@article{single_AGLC_GAN,
  title    = {AGLC-GAN: Attention-based global-local cycle-consistent generative adversarial networks for unpaired single image dehazing},
  journal  = {Image and Vision Computing},
  volume   = {140},
  pages    = {104859},
  year     = {2023},
  issn     = {0262-8856},
  doi      = {https://doi.org/10.1016/j.imavis.2023.104859},
  url      = {https://www.sciencedirect.com/science/article/pii/S0262885623002330},
  author   = {R.S. Jaisurya and Snehasis Mukherjee},
  keywords = {Image Dehazing, CycleGAN, Attention, Unpaired}
}

@article{single_PNBT_CR,
  author   = {Yan, Yiming and He, Yanming and Su, Nan and He, Guangjun and Fu, Han},
  journal  = {IEEE Geoscience and Remote Sensing Letters},
  title    = {PNBT-CR: A Cloud Removal Method for Ship Detection},
  year     = {2024},
  volume   = {21},
  number   = {},
  pages    = {1-5},
  keywords = {Marine vehicles;Clouds;Image restoration;Training;Decoding;Feature extraction;Testing;Cloud occlusion;cloud removal;deep learning;image restoration;ship detection},
  doi      = {10.1109/LGRS.2024.3361150}
}

@article{single_CGAN_scattering_martian,
  author   = {Ye, Hongxia and Xiang, Haiyue and Xu, Feng},
  journal  = {IEEE Transactions on Geoscience and Remote Sensing},
  title    = {Cycle-GAN Network Incorporated With Atmospheric Scattering Model for Dust Removal of Martian Optical Images},
  year     = {2024},
  volume   = {62},
  number   = {},
  pages    = {1-13},
  keywords = {Atmospheric modeling;Scattering;Optical scattering;Optical imaging;Optical sensors;Image restoration;Atmosphere;Atmospheric scattering model;curiosity rover;cycle-consistent generative adversarial network (Cycle-GAN);dust removal;Martian optical images},
  doi      = {10.1109/TGRS.2024.3432601}
}

@misc{GLF_CR,
  title         = {GLF-CR: SAR-Enhanced Cloud Removal with Global-Local Fusion},
  author        = {Fang Xu and Yilei Shi and Patrick Ebel and Lei Yu and Gui-Song Xia and Wen Yang and Xiao Xiang Zhu},
  year          = {2022},
  eprint        = {2206.02850},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV},
  url           = {https://arxiv.org/abs/2206.02850}
}

@article{expl_ML_CR_Cameroon,
  author  = {Mvogo, Joseph Ngono and Noumsi, Woguia Auguste Vigny and Wirba, Pountianus Berinyuy},
  title   = {Exploration of machine learning techniques for cloud removal and gap filling on Sentinel-2 time series images for better exploitation in far North Cameroon},
  journal = {Discover Applied Sciences},
  year    = {2025},
  volume  = {7},
  number  = {8},
  pages   = {843},
  doi     = {10.1007/s42452-025-07026-w},
  url     = {https://doi.org/10.1007/s42452-025-07026-w},
  issn    = {3004-9261}
}

@article{RS_Data_Fusion_GANs_sota,
  author   = {Liu, Peng and Li, Jun and Wang, Lizhe and He, Guojin},
  journal  = {IEEE Geoscience and Remote Sensing Magazine},
  title    = {Remote Sensing Data Fusion With Generative Adversarial Networks: State-of-the-art methods and future research directions},
  year     = {2022},
  volume   = {10},
  number   = {2},
  pages    = {295-328},
  keywords = {Data integration;Generators;Generative adversarial networks;Computer architecture;Degradation;Data models;Image fusion},
  doi      = {10.1109/MGRS.2022.3165967}
}

@article{genAI_HS_sens_data_review,
  author   = {Abuhani, Diaa Addeen and Zualkernan, Imran and Aldamani, Raghad and Alshafai, Mohamed},
  journal  = {IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
  title    = {Generative Artificial Intelligence for Hyperspectral Sensor Data: A Review},
  year     = {2025},
  volume   = {18},
  number   = {},
  pages    = {6422-6439},
  keywords = {Feature extraction;Hyperspectral imaging;Image segmentation;Satellites;Spatial resolution;Machine learning;Neural networks;Reviews;Noise measurement;Data models;Diffusion models;generative adversarial networks (GANs);generative artificial intelligence (GAI);generative neural networks (GNNs);hyperspectral images},
  doi      = {10.1109/JSTARS.2025.3538759}
}

@misc{GANs_Goodfellow,
  title         = {Generative Adversarial Networks},
  author        = {Ian J. Goodfellow and Jean Pouget-Abadie and Mehdi Mirza and Bing Xu and David Warde-Farley and Sherjil Ozair and Aaron Courville and Yoshua Bengio},
  year          = {2014},
  eprint        = {1406.2661},
  archiveprefix = {arXiv},
  primaryclass  = {stat.ML},
  url           = {https://arxiv.org/abs/1406.2661}
}

@misc{DDPM_2020,
  title         = {Denoising Diffusion Probabilistic Models},
  author        = {Jonathan Ho and Ajay Jain and Pieter Abbeel},
  year          = {2020},
  eprint        = {2006.11239},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2006.11239}
}

@article{IHS_wavelet_Zhang2019,
  author  = {Zhang, Wenyuan and Xu, Min},
  title   = {Translate SAR Data into Optical Image Using IHS and Wavelet Transform Integrated Fusion},
  journal = {Journal of the Indian Society of Remote Sensing},
  year    = {2019},
  volume  = {47},
  number  = {1},
  pages   = {125--137},
  doi     = {10.1007/s12524-018-0879-7},
  url     = {https://doi.org/10.1007/s12524-018-0879-7},
  issn    = {0974-3006}
}

@misc{pix2pix_2018,
  title         = {Image-to-Image Translation with Conditional Adversarial Networks},
  author        = {Phillip Isola and Jun-Yan Zhu and Tinghui Zhou and Alexei A. Efros},
  year          = {2018},
  eprint        = {1611.07004},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV},
  url           = {https://arxiv.org/abs/1611.07004}
}

@misc{U-net_2015,
  title         = {U-Net: Convolutional Networks for Biomedical Image Segmentation},
  author        = {Olaf Ronneberger and Philipp Fischer and Thomas Brox},
  year          = {2015},
  eprint        = {1505.04597},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV},
  url           = {https://arxiv.org/abs/1505.04597}
}

@misc{adam_optimizer_2017,
  title         = {Adam: A Method for Stochastic Optimization},
  author        = {Diederik P. Kingma and Jimmy Ba},
  year          = {2017},
  eprint        = {1412.6980},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/1412.6980}
}
@inproceedings{kiwa_auto_Delineation_BAs,
  author    = {Hofmann, Peter and Trofanisin, Nichita and Wöllmann, Sebastian},
  booktitle = {2024 14th International Conference on Advanced Computer Information Technologies (ACIT)},
  title     = {Automatic Delineation of Burned Forest Areas from Satellite Imagery to Analyze and Manage Wildfires},
  year      = {2024},
  volume    = {},
  number    = {},
  pages     = {766-771},
  keywords  = {Wildfires;Automation;Forestry;Satellite images;Reliability;Information technology;Remote sensing;Remote Sensing;Wildfire Detection and Analysis;Image Analysis},
  doi       = {10.1109/ACIT62333.2024.10712578}
}

@online{THD_ZAF,
  author = {{Technische Hochschule Deggendorf}},
  title  = {{Zentrum für Angewandte Forschung (ZAF)}},
  year   = {2025},
  url    = {https://zaf.th-deg.de/},
  note   = {Accessed: Sep. 19, 2025}
}

@online{KIWA_Project,
  author = {{KIWA Project}},
  title  = {{KI-basierte Waldüberwachung – AI-based Forest Monitoring}},
  year   = {2025},
  url    = {https://www.kiwa-projekt.de/eng/home},
  note   = {Accessed: Sep. 19, 2025}
}


@article{quality_assessment_S2OT,
  author         = {Zhang, Jiexin and Zhou, Jianjiang and Li, Minglei and Zhou, Huiyu and Yu, Tianzhu},
  title          = {Quality Assessment of SAR-to-Optical Image Translation},
  journal        = {Remote Sensing},
  volume         = {12},
  year           = {2020},
  number         = {21},
  article-number = {3472},
  url            = {https://www.mdpi.com/2072-4292/12/21/3472},
  issn           = {2072-4292},
  doi            = {10.3390/rs12213472}
}

@article{c_guided_fus_s2ot,
  author   = {Xiang, Xuanyu and Tan, Yihua and Yan, Longfei},
  journal  = {IEEE Transactions on Geoscience and Remote Sensing},
  title    = {Cloud-Guided Fusion With SAR-to-Optical Translation for Thick Cloud Removal},
  year     = {2024},
  volume   = {62},
  number   = {},
  pages    = {1-15},
  keywords = {Clouds;Cloud computing;Optical imaging;Radar polarimetry;Fats;Optical sensors;Feature extraction;Cloud removal;data fusion;deep learning;generative adversarial network (GAN);synthetic aperture radar (SAR)-to-optical translation},
  doi      = {10.1109/TGRS.2024.3431556}
}

@article{transfusion_cr,
  author   = {Liu, Rui and Meng, Siqi and Peng, Yini and Tian, Xin},
  journal  = {IEEE Transactions on Geoscience and Remote Sensing},
  title    = {TransFusion-CR: Two-Phase SAR-to-Optical Translation and Deep Feature Fusion for Cloud Removal},
  year     = {2024},
  volume   = {62},
  number   = {},
  pages    = {1-11},
  keywords = {Clouds;Synthetic aperture radar;Radar polarimetry;Optical imaging;Feature extraction;Optical sensors;Task analysis;Cloud removal;data fusion;deep learning;multispectral image (MSI);synthetic aperture radar (SAR)},
  doi      = {10.1109/TGRS.2024.3439854}
}
@article{trans_gan_CF,
  author   = {Li, Congyu and Liu, Xinxin and Li, Shutao},
  journal  = {IEEE Transactions on Geoscience and Remote Sensing},
  title    = {Transformer Meets GAN: Cloud-Free Multispectral Image Reconstruction via Multisensor Data Fusion in Satellite Images},
  year     = {2023},
  volume   = {61},
  number   = {},
  pages    = {1-13},
  keywords = {Clouds;Optical sensors;Optical imaging;Cloud computing;Image reconstruction;Adaptive optics;Synthetic aperture radar;Cloud removal;generative adversarial network (GAN);image fusion;optical image;synthetic aperture radar (SAR) image;transformer},
  doi      = {10.1109/TGRS.2023.3326545}
}

@article{hvt_cgan,
  author   = {Zhao, Wenbo and Jiang, Nana and Liao, Xiaoxin and Zhu, Jubo},
  journal  = {IEEE Transactions on Geoscience and Remote Sensing},
  title    = {HVT-cGAN: Hybrid Vision Transformer cGAN for SAR-to-Optical Image Translation},
  year     = {2025},
  volume   = {63},
  number   = {},
  pages    = {1-17},
  keywords = {Optical sensors;Optical imaging;Transformers;Generative adversarial networks;Translation;Radar polarimetry;Adaptive optics;Optical interferometry;Computer vision;Training;Generative adversarial network (GAN);hybrid vision transformer (ViT);image translation;synthetic aperture radar (SAR)},
  doi      = {10.1109/TGRS.2024.3523040}
}

@inproceedings{msf_gan,
  author    = {Chen, YongKang and Zhu, Zuguo and Huang, Yan and Wang, Peng and Huang, Bo and Mura, Mauro Dalla},
  booktitle = {IGARSS 2024 - 2024 IEEE International Geoscience and Remote Sensing Symposium},
  title     = {MSF: A Multi-Scale Fusion Generative Adversarial Network for SAR-to-Optical Image Translation},
  year      = {2024},
  volume    = {},
  number    = {},
  pages     = {9058-9061},
  keywords  = {Image synthesis;Semantics;Optical fiber networks;Feature extraction;Optical imaging;Generative adversarial networks;Radar polarimetry;SAR-to-optical image translation;multi-scale fusion generative adversarial network;multi-scale fusion generator (MFG)},
  doi       = {10.1109/IGARSS53475.2024.10640486}
}

@article{diffusion_memory,
  author   = {Guo, Zhe and Liu, Jiayi and Cai, Qinglin and Zhang, Zhibo and Mei, Shaohui},
  journal  = {IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
  title    = {Learning SAR-to-Optical Image Translation via Diffusion Models With Color Memory},
  year     = {2024},
  volume   = {17},
  number   = {},
  pages    = {14454-14470},
  keywords = {Image color analysis;Optical imaging;Diffusion models;Optical sensors;Optical distortion;Radar polarimetry;Adaptive optics;Brownian bridge diffusion structure;color memory;diffusion models;synthetic aperture radar (SAR)-to-optical image translation (S2OIT)},
  doi      = {10.1109/JSTARS.2024.3439516}
}

@article{cond_brownian,
  title     = {Conditional Brownian Bridge Diffusion Model for VHR SAR to Optical Image Translation},
  volume    = {22},
  issn      = {1558-0571},
  url       = {http://dx.doi.org/10.1109/LGRS.2025.3562401},
  doi       = {10.1109/lgrs.2025.3562401},
  journal   = {IEEE Geoscience and Remote Sensing Letters},
  publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
  author    = {Kim, Seon-Hoon and Chung, Daewon},
  year      = {2025},
  pages     = {1–5}
}

@article{iqa_ssim,
  author  = {Wang, Zhou and Bovik, Alan and Sheikh, Hamid and Simoncelli, Eero},
  year    = {2004},
  month   = {05},
  pages   = {600 - 612},
  title   = {Image Quality Assessment: From Error Visibility to Structural Similarity},
  volume  = {13},
  journal = {Image Processing, IEEE Transactions on},
  doi     = {10.1109/TIP.2003.819861}
}

@article{iqa_psnr,
  title    = {Visual-PSNR measure of image quality},
  journal  = {Journal of Visual Communication and Image Representation},
  volume   = {25},
  number   = {5},
  pages    = {874-878},
  year     = {2014},
  issn     = {1047-3203},
  doi      = {https://doi.org/10.1016/j.jvcir.2014.01.008},
  url      = {https://www.sciencedirect.com/science/article/pii/S1047320314000091},
  author   = {Alexander Tanchenko},
  keywords = {Image quality, Objective measure of image quality, Peak signal-to-noise ratio, Block-based compression algorithm, Subjective image quality, Image database, Mean opinion score, Human visual system}
}

@misc{iqa_lpips,
  title         = {The Unreasonable Effectiveness of Deep Features as a Perceptual Metric},
  author        = {Richard Zhang and Phillip Isola and Alexei A. Efros and Eli Shechtman and Oliver Wang},
  year          = {2018},
  eprint        = {1801.03924},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV},
  url           = {https://arxiv.org/abs/1801.03924}
}

@misc{iqa_fid,
  title         = {GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium},
  author        = {Martin Heusel and Hubert Ramsauer and Thomas Unterthiner and Bernhard Nessler and Sepp Hochreiter},
  year          = {2018},
  eprint        = {1706.08500},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/1706.08500}
}

@article{iqa_sam,
title = {The spectral image processing system (SIPS)—interactive visualization and analysis of imaging spectrometer data},
journal = {Remote Sensing of Environment},
volume = {44},
number = {2},
pages = {145-163},
year = {1993},
note = {Airbone Imaging Spectrometry},
issn = {0034-4257},
doi = {https://doi.org/10.1016/0034-4257(93)90013-N},
url = {https://www.sciencedirect.com/science/article/pii/003442579390013N},
author = {F.A. Kruse and A.B. Lefkoff and J.W. Boardman and K.B. Heidebrecht and A.T. Shapiro and P.J. Barloon and A.F.H. Goetz},
abstract = {The Center for the Study of Earth from Space (CSES) at the University of Colorado, Boulder, has developed a prototype interactive software system called the Spectral Image Processing System (SIPS) using IDL (the Interactive Data Language) on UNIX-based workstations. SIPS is designed to take advantage of the combination of high spectral resolution and spatial data presentation unique to imaging spectrometers. It streamlines analysis of these data by allowing scientists to rapidly interact with entire datasets. SIPS provides visualization tools for rapid exploratory analysis and numerical tools for quantitative modeling. The user interface is X-Windows-based, user friendly, and provides “point and click” operation. SIPS is being used for multidisciplinary research concentrating on use of physically based analysis methods to enhance scientific results from imaging spectrometer data. The objective of this continuing effort is to develop operational techniques for quantitative analysis of imaging spectrometer data and to make them available to the scientific community prior to the launch of imaging spectrometer satellite systems such as the Earth Observing System (EOS) High Resolution Imaging Spectrometer (HIRIS).}
}